{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call API to get GPT's outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zeu3IYvuA-J"
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qnnCdcD4tFM0"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "os.chdir(\"/Users/wq/Desktop/AI Tutor/Abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgJGhPXZt2yU",
    "outputId": "f19f399e-d1e0-4a0c-f4af-d56d883b94e5"
   },
   "outputs": [],
   "source": [
    "#openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper content\n",
    "with open('page.json', 'r') as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "\n",
    "new_paper=[]\n",
    "for paper in papers:\n",
    "    new_paper.append(paper['paper_info'])\n",
    "\n",
    "len(new_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       " 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       " 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mofsIv2tuFvn",
    "outputId": "315e9a5e-e0cb-4a1d-8e9d-544bf32a8fd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备要输入到 ChatGPT 模型的多个 prompt \n",
    "prompts = []\n",
    "for p in new_paper:\n",
    "    p = f\"Please give me some information based on parts of the paper: {p} Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:\"\n",
    "    prompts.append(p)\n",
    "\n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please give me some information based on parts of the paper: LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:',\n",
       " 'Please give me some information based on parts of the paper: We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:',\n",
       " 'Please give me some information based on parts of the paper: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ZaoTXYEmt8PQ",
    "outputId": "2007a51f-4ad3-4203-d822-84fe6e600625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1920903007189432"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 遍历多个 prompt 并使用 OpenAI API 发送请求并获取响应\n",
    "start = time.time()\n",
    "\n",
    "results = []\n",
    "for prompt in prompts:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    # 从响应中获取 ChatGPT 生成的文本\n",
    "    generated_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # 将 prompt 和生成的文本组成一个字典并添加到 results 数组中\n",
    "    result = {\n",
    "        \"instruction\": prompt,\n",
    "        \"input\": \"\",\n",
    "        \"output\": generated_text,\n",
    "    }\n",
    "    results.append(result)\n",
    "    #time.sleep(15)\n",
    "\n",
    "end = time.time()\n",
    "duration = (end - start)/60\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "W4KXeqLrt-1J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "results\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "3D-obWyaubUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"instruction\": \"Please give me some information based on parts of the paper: LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:\", \"input\": \"\", \"output\": \"1. Title: LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions \\n2. Author names: Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji \\n3. Keywords: Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM \\n4. Research Background: Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. \\n5. Research Methodology: The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. \\n6. Conclusion: The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.\"}, {\"instruction\": \"Please give me some information based on parts of the paper: We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:\", \"input\": \"\", \"output\": \"1. Title: We’re Afraid Language Models Aren’t Modeling Ambiguity\\n2. Author names: Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi\\n3. Keywords: ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language\\n4. Research Background: Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.\\n5. Research Methodology: The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. \\n6. Conclusion: The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.\"}, {\"instruction\": \"Please give me some information based on parts of the paper: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:\", \"input\": \"\", \"output\": \"1. Title: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\n2. Author names: JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU\\n3. Keywords: Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence\\n4. Research Background: The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.\\n5. Research Methodology: The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.\\n6. Conclusion: The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\"}]\n"
     ]
    }
   ],
   "source": [
    "# 将 results 数组转换成 JSON 格式并打印\n",
    "json_data = json.dumps(results, ensure_ascii=False)\n",
    "print(json_data.encode('utf-8').decode('utf-8'))\n",
    "\n",
    "# 保存 results 数组到 results.json 文件中\n",
    "with open(\"AIpaper.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer the output into traning data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Please give me some information based on parts of the paper: LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:',\n",
       "  'input': '',\n",
       "  'output': '1. Title: LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions \\n2. Author names: Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji \\n3. Keywords: Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM \\n4. Research Background: Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. \\n5. Research Methodology: The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. \\n6. Conclusion: The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.'},\n",
       " {'instruction': 'Please give me some information based on parts of the paper: We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:',\n",
       "  'input': '',\n",
       "  'output': '1. Title: We’re Afraid Language Models Aren’t Modeling Ambiguity\\n2. Author names: Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi\\n3. Keywords: ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language\\n4. Research Background: Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.\\n5. Research Methodology: The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. \\n6. Conclusion: The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.'},\n",
       " {'instruction': 'Please give me some information based on parts of the paper: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n Your response should be in the following format: \\n1.Title: \\n2.Author names: \\n3.Keywords: \\n4.Research Background: \\n5.Research Methodology: \\n6.Conclusion:',\n",
       "  'input': '',\n",
       "  'output': '1. Title: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\n2. Author names: JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU\\n3. Keywords: Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence\\n4. Research Background: The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.\\n5. Research Methodology: The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.\\n6. Conclusion: The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### read the output\n",
    "with open('RLpaper.json', 'r') as file:\n",
    "    # Load the JSON data into a list\n",
    "    results = json.load(file)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mark the title of the given paper.',\n",
       " \"List all the authors' names.\",\n",
       " 'Mark the keywords of this paper and give their definitions.',\n",
       " 'Summarize the given introduction to generate the research background of this paper.',\n",
       " 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       " \"Give a conclusion about this paper's major achievements and breakthroughs.\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = [\"Mark the title of the given paper.\",\"List all the authors' names.\",\"Mark the keywords of this paper and give their definitions.\",\"Summarize the given introduction to generate the research background of this paper.\",\"List all the research methodologies proposed by this paper and summarize their details.\",\"Give a conclusion about this paper's major achievements and breakthroughs.\"]\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paper[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindts = []\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    for n in range(6):\n",
    "        traindt = {\n",
    "        \"instruction\": instruction[n],\n",
    "        \"input\": new_paper[i],\n",
    "        \"output\": r['output'].split('\\n')[n],\n",
    "    }\n",
    "        traindts.append(traindt)\n",
    "\n",
    "len(traindts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '1. Title: LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions '},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '2. Author names: Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji '},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '3. Keywords: Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM '},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '4. Research Background: Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. '},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '5. Research Methodology: The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. '},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '6. Conclusion: The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.'},\n",
       " {'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '1. Title: We’re Afraid Language Models Aren’t Modeling Ambiguity'},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '2. Author names: Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi'},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '3. Keywords: ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language'},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '4. Research Background: Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.'},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '5. Research Methodology: The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. '},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '6. Conclusion: The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.'},\n",
       " {'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '1. Title: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond'},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '2. Author names: JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU'},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '3. Keywords: Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence'},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '4. Research Background: The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.'},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '5. Research Methodology: The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.'},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': '6. Conclusion: The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"instruction\": \"Mark the title of the given paper.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"1. Title: LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions \"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"2. Author names: Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji \"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"3. Keywords: Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM \"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"4. Research Background: Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. \"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"5. Research Methodology: The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. \"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"6. Conclusion: The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.\"}, {\"instruction\": \"Mark the title of the given paper.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"1. Title: We’re Afraid Language Models Aren’t Modeling Ambiguity\"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"2. Author names: Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi\"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"3. Keywords: ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language\"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"4. Research Background: Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.\"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"5. Research Methodology: The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. \"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"6. Conclusion: The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.\"}, {\"instruction\": \"Mark the title of the given paper.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"1. Title: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"2. Author names: JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU\"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"3. Keywords: Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence\"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"4. Research Background: The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.\"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"5. Research Methodology: The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.\"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"6. Conclusion: The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\"}]\n"
     ]
    }
   ],
   "source": [
    "# 将 results 数组转换成 JSON 格式并打印\n",
    "json_data = json.dumps(traindts, ensure_ascii=False)\n",
    "print(json_data.encode('utf-8').decode('utf-8'))\n",
    "\n",
    "# 保存 results 数组到 results.json 文件中\n",
    "with open(\"AIpaper.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(traindts, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the JSON file into a list of dictionaries\n",
    "with open('AIpaper.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# loop through the list of dictionaries\n",
    "for d in data:\n",
    "    # remove the prefix from each line of the 'output' key\n",
    "    d['output'] = '\\n'.join(line.split(': ', 1)[1] for line in d['output'].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions '},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji '},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM '},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. '},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. '},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.'},\n",
       " {'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'We’re Afraid Language Models Aren’t Modeling Ambiguity'},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi'},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language'},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.'},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. '},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.'},\n",
       " {'instruction': 'Mark the title of the given paper.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond'},\n",
       " {'instruction': \"List all the authors' names.\",\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU'},\n",
       " {'instruction': 'Mark the keywords of this paper and give their definitions.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence'},\n",
       " {'instruction': 'Summarize the given introduction to generate the research background of this paper.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.'},\n",
       " {'instruction': 'List all the research methodologies proposed by this paper and summarize their details.',\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.'},\n",
       " {'instruction': \"Give a conclusion about this paper's major achievements and breakthroughs.\",\n",
       "  'input': 'Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n',\n",
       "  'output': 'The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"instruction\": \"Mark the title of the given paper.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions \"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji \"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Large language models, instruction tuning, distillation, diverse dataset, LaMini-LM \"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Large language models (LLMs) with instruction tuning have shown exceptional generative capabilities but require significant computational resources. The paper proposes LaMini-LM, a collection of language models that are smaller in size than existing instruction-tuned models. The authors generate a diverse instruction dataset and use it for sequence distillation to develop a set of LaMini-LM models. \"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The authors generate a large-scale instruction dataset comprising both existing and newly-generated instructions. They use GPT-3.5-turbo to generate responses for these instructions and then distill the knowledge to tune a host of models of varying sizes. They evaluate the performance of LaMini-LM models on 15 different NLP benchmarks both automatically and manually. \"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"LaMini-LM: A Diverse Herd of Distilled Models\\nfrom Large-Scale Instructions\\nMinghao Wu1,2∗Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\\n1Mohamed bin Zayed University of Artiﬁcial Intelligence\\n2Monash University\\n3The University of British Columbia\\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\\nAbstract\\nLarge language models (LLMs) with instruc-\\ntion ﬁnetuning demonstrate superior genera-\\ntive capabilities. However, these models are\\nresource intensive. To alleviate this issue, we\\nexplore distilling knowledge from instruction-\\ntuned LLMs to much smaller ones. To this end,\\nwe carefully develop a large set of 2.58M in-\\nstructions based on both existing and newly-\\ngenerated instructions.\\nIn addition to being\\nsizeable, we design our instructions to cover\\na broad set of topics to ensure. A thorough in-\\nvestigation of our instruction data demonstrate\\ntheir diversity, and we generate responses for\\nthese instructions using gpt-3.5-turbo. We\\nthen exploit the instructions to tune a host\\nof models, dubbed LaMini-LM, of varying\\nsizes, both from the encoder-decoder as well\\nas the decoder-only families.\\nWe evaluate\\nour models both automatically (on 15 differ-\\nent NLP benchmarks) and manually. Results\\nshow that our proposed LaMini-LM are on par\\nwith competitive baselines while being nearly\\n×10 smaller in size.1\\n1\\nIntroduction\\nLarge language models (LLMs) with instruction\\ntuning are capable of generating remarkable out-\\nputs for a wide range of use cases (Ouyang et al.,\\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\\net al., 2022; OpenAI, 2023). However, these mod-\\nels usually have billions of parameters, which re-\\nquire massive computational resources for both\\ntraining and inference (Brown et al., 2020; Thop-\\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\\nhery et al., 2022). Kaplan et al. (2020) suggest\\nthat the performance of LLMs scales proportion-\\nally with model and dataset size. Consequently,\\nscaling the models raises many issues such as those\\nrelated to the energy footprint (Strubell et al., 2019).\\n∗ work done while visiting MBZUAI\\n1Our code, model checkpoints, and dataset are available at\\nhttps://github.com/mbzuai-nlp/LaMini-LM\\n+\\nGenerate\\nExisting\\nInstructions\\nGPT2\\n+\\nGenerate\\nFine-tune\\nT5\\nNeo\\nLaMini-LM\\nC.\\nModels\\nSeed\\nInstructions\\nSynthetic\\nInstructions\\nSynthetic \\nResponses\\nLaMini-Instruction dataset\\nFigure 1: Overview of LaMini-LM\\nMoreover, the accessibility of large models is a real\\nconcern for many NLP practitioners due to lim-\\nited access to computing resources (Nityasya et al.,\\n2020).\\nIn this work, we present LaMini-LM, a collec-\\ntion of language models that are notably smaller\\nin size than most existing instruction-tuned mod-\\nels. We develop LaMini-LM models by employing\\nsequence distillation (also known as ofﬂine distilla-\\ntion) (Kim and Rush, 2016) from LLMs. Although\\nsimilar attempts have been made in recent work\\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\\net al., 2023)), there are several gaps in this literature\\nthat we aim to address. Speciﬁcally, these works\\noften (i) provide a small-scale distilled dataset (ii)\\nthat is not necessarily diverse, and a (iii) limited\\nnumber of models (typically only one), (iv) with-\\nout comprehensive evaluation nor analysis of the\\nmodels’ performance. Furthermore, many of the\\ndistilled models resulting from prior work tend to\\nstill be relatively computationally intensive. That\\nis, parameters of these recent models usually range\\nfrom 7B to 13B, making them difﬁcult to deploy in\\nresource-constrained settings especially for under-\\nresourced institutions.\\nTo alleviate these issues, we ﬁrstly generate a\\nlarge-scale ofﬂine distillation dataset comprising\\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The authors present LaMini-LM, a collection of language models that are nearly 10 times smaller in size than competitive baselines while being on par with their performance. They address the limitations of previous work in terms of dataset size, diversity, number of models, evaluation, and computational intensity. Overall, LaMini-LM provides a resource-efficient solution for NLP practitioners with limited access to computing resources.\"}, {\"instruction\": \"Mark the title of the given paper.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi\"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"ambiguity, language models, natural language understanding, benchmark, evaluation, disentangling meanings, misleading language\"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Ambiguity is an intrinsic feature of natural language and managing it is crucial for effective communication. However, the ability of language models to recognize and handle ambiguity remains understudied. This paper presents AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper also designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings.\"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The paper collects AMBIENT, a benchmark dataset of 1,645 linguist-annotated examples of diverse kinds of ambiguity. The paper designs a suite of tests based on AMBIENT to evaluate the ability of pretrained language models to recognize and disentangle possible meanings. The paper conducts an evaluation of pretrained language models, including GPT-4, on the task of recognizing ambiguity and disentangling possible meanings. \"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"We’re Afraid Language Models Aren’t Modeling Ambiguity\\nAlisa Liu♡\\nZhaofeng Wu♦\\nJulian Michael♠\\nAlane Suhr♣\\nPeter West♡\\nAlexander Koller♥♣\\nSwabha Swayamdipta♢\\nNoah A. Smith♡♣\\nYejin Choi♡♣\\n♡Paul G. Allen School of Computer Science & Engineering, University of Washington\\n♣Allen Institute for Artiﬁcial Intelligence\\n♢University of Southern California\\n♥Saarland University\\n♠New York University\\n♦Massachusetts Institute of Technology\\nalisaliu@cs.washington.edu\\nAbstract\\nAmbiguity is an intrinsic feature of natural lan-\\nguage. Managing ambiguity is a key part of\\nhuman language understanding, allowing us\\nto anticipate misunderstanding as communica-\\ntors and revise our interpretations as listeners.\\nAs language models (LMs) are increasingly\\nemployed as dialogue interfaces and writing\\naids, handling ambiguous language is critical\\nto their success. We characterize ambiguity in\\na sentence by its effect on entailment relations\\nwith another sentence, and collect AMBIENT,1\\na linguist-annotated benchmark of 1,645 exam-\\nples with diverse kinds of ambiguity. We de-\\nsign a suite of tests based on AMBIENT, pre-\\nsenting the ﬁrst evaluation of pretrained LMs\\nto recognize ambiguity and disentangle possi-\\nble meanings. We ﬁnd that the task remains ex-\\ntremely challenging, including for the recent\\nGPT-4, whose generated disambiguations are\\nconsidered correct only 32% of the time in\\nhuman evaluation, compared to 90% for dis-\\nambiguations in our dataset. Finally, to illus-\\ntrate the value of ambiguity-sensitive tools, we\\nshow that a multilabel NLI model can ﬂag po-\\nlitical claims in the wild that are misleading\\ndue to ambiguity. We encourage the ﬁeld to re-\\ndiscover the importance of ambiguity for NLP.\\n1\\nIntroduction\\nAmbiguity seems to be an essential, in-\\ndispensable element for the transfer of\\ninformation from one place to another by\\nwords. — Thomas (1974), as referenced\\nin the epilogue of Grosz (1977)\\nAmbiguity is an intrinsic feature of language, al-\\nlowing speakers to balance efﬁciency and clarity\\nin communication (Zipf, 1949; Piantadosi et al.,\\n2012). Language understanding thus requires rec-\\nognizing the presence of multiple interpretations:\\n1Data and code can be found at https://github.com/\\nalisawuffles/ambient\\nFigure 1: Ambiguity can be the result of innocent mis-\\ncommunication (top), or deliberately used to mislead\\none’s listeners (bottom). For instance, if the cat is con-\\nfused about its whereabouts after leaving the house,\\nthen it is lost in the sense of being unable to ﬁnd its way\\n(entailment edge); if it has not returned home in many\\ndays, then it is lost in the sense that others cannot lo-\\ncate it (neutral edge). Each example in AMBIENT con-\\ntains a set of labels corresponding to plausible readings,\\nalong with a disambiguating rewrite for each reading.\\nas communicators, we anticipate the possibility of\\nmisunderstanding; as listeners, we ask clarifying\\nquestions, disambiguate meanings on the basis of a\\nwide range of contextual factors, and backtrack and\\nrevise our earlier interpretations as needed. Beyond\\nunintended miscommunication, ambiguity is also\\nan effective tool for sending covert messages, e.g.,\\nout of politeness or to mislead one’s listeners while\\navoiding accountability (see Figure 1).\\nAs language models (LMs) are increasingly em-\\nployed to act as dialogue agents (OpenAI, 2022;\\nShuster et al., 2022) or to aid human communica-\\ntion as writing aids (Lee et al., 2022), being able\\nto work with ambiguous language will make them\\nmore effective. This skill would support adaptation\\nto different contexts, clearer communication, and\\nidentiﬁcation of misleading or deceptive language.\\nYet, the ability of pretrained LMs to recognize am-\\nbiguity and disentangle possible meanings remains\\nunstudied, partly because ambiguous instances are\\nsystematically excluded in the curation of bench-\\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The paper finds that recognizing and disentangling possible meanings from ambiguous language remains a challenging task for pretrained language models, including the recent GPT-4. The paper emphasizes the importance of ambiguity for natural language understanding and encourages the field to develop ambiguity-sensitive tools. The paper also shows how a multilabel NLI model can flag political claims in the wild that are misleading due to ambiguity, highlighting the practical value of ambiguity-sensitive tools.\"}, {\"instruction\": \"Mark the title of the given paper.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\"}, {\"instruction\": \"List all the authors' names.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"JINGFENG YANG, HONGYE JIN, RUIXIANG TANG, XIAOTIAN HAN, QIZHANG FENG, HAOMING JIANG, BING YIN, XIA HU\"}, {\"instruction\": \"Mark the keywords of this paper and give their definitions.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"Large Language Models, Natural Language Processing, Natural Language Understanding, Natural Language Generation, Machine Translation, Practical Guide, Neural Language Processing, Artificial General Intelligence\"}, {\"instruction\": \"Summarize the given introduction to generate the research background of this paper.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The paper focuses on the practical aspects of working with Large Language Models (LLMs) in downstream natural language processing (NLP) tasks. It provides insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. The paper aims to provide a guide for practitioners and end-users to enable the successful implementation of LLMs in a wide range of NLP tasks.\"}, {\"instruction\": \"List all the research methodologies proposed by this paper and summarize their details.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The paper presents a comprehensive and practical guide based on discussions and insights into the usage of LLMs. The authors offer an introduction and brief summary of current GPT- and BERT-style LLMs. They discuss the influence of pre-training data, training data, and test data. They also provide a detailed discussion about the use and non-use cases of LLMs for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks. The paper presents various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. The authors also explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency.\"}, {\"instruction\": \"Give a conclusion about this paper's major achievements and breakthroughs.\", \"input\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\\nJINGFENG YANG∗, Amazon, USA\\nHONGYE JIN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nRUIXIANG TANG∗, Department of Computer Science, Rice University, USA\\nXIAOTIAN HAN∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nQIZHANG FENG∗, Department of Computer Science and Engineering, Texas A&M University, USA\\nHAOMING JIANG, Amazon, USA\\nBING YIN, Amazon, USA\\nXIA HU, Department of Computer Science, Rice University, USA\\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\\nCCS Concepts: • Computing methodologies → Natural language processing; Natural language generation; Machine trans-\\nlation.\\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\\n1\\nINTRODUCTION\\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\\ncapabilities and limitations, as well as the data and tasks involved in NLP.\\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\\n∗These authors contributed equally.\\nAuthors’ addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\\n1\\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\\n\", \"output\": \"The paper provides valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. The comprehensive guide aims to provide researchers and practitioners with practical advice on why or why not to choose LLMs for a given task. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\"}]\n"
     ]
    }
   ],
   "source": [
    "# 将 results 数组转换成 JSON 格式并打印\n",
    "json_data = json.dumps(data, ensure_ascii=False)\n",
    "print(json_data.encode('utf-8').decode('utf-8'))\n",
    "\n",
    "# 保存 results 数组到 results.json 文件中\n",
    "with open(\"AIpaper.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
