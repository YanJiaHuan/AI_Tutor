{
    "Abstract": "Abstractions and  Deep Neural Networks.   Reimers, N., & Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-networks.  arXiv preprint arXiv:1908.10084.   Sadeghnejad-Barkousaraie, A., Bohara, G., Jiang, S., & Nguyen, D. (2021). A reinforcement learning  application of a guided Monte Carlo Tree Search algorithm for beam orientation selection in  radiation therapy. Machine Learning: Science and Technology, 2(3), 035013.   Sahba, F., Tizhoosh, H. R., & Salama, M. M. A. (2006, 16-21 July 2006). A Reinforcement Learning  Framework for Medical Image Segmentation. The 2006 IEEE International Joint Conference on  Neural Network Proceedings,   Sallab, A. E. L., Abdou, M., Perot, E., & Yogamani, S. (2017). Deep Reinforcement Learning Framework for  Autonomous Driving. Electronic Imaging, 2017(19), 70\u201376-70\u201376.   Sewak, M. (2019). Actor-Critic Models and the A3C. In Deep Reinforcement Learning: Frontiers of  Artificial Intelligence (pp. 141-152). Springer Singapore. https://doi.org/10.1007/978-981-13-82857_11   Sharma, A. R., & Kaushik, P. (2017). Literature Survey of Statistical, Deep and Reinforcement Learning in  Natural Language Processing. 2017 International Conference on Computing, Communication and  Automation (ICCCA),   Shen, C., Gonzalez, Y., Klages, P., Qin, N., Jung, H., Chen, L., Nguyen, D., Jiang, S. B., & Jia, X. (2019).  Intelligent inverse treatment planning via deep reinforcement learning, a proof-of-principle study  in high dose-rate brachytherapy for cervical cancer. Physics in Medicine & Biology, 64(11), 115013.   Shen, C., Nguyen, D., Chen, L., Gonzalez, Y., McBeth, R., Qin, N., Jiang, S. B., & Jia, X. (2020). Operating a  treatment planning system using a deep\u2010reinforcement learning\u2010based virtual treatment planner for  prostate cancer intensity\u2010modulated radiation therapy treatment planning. Medical physics, 47(6),  2329-2336.   Shen, D., Wu, G., & Suk, H.-I. (2017). Deep Learning in Medical Image Analysis. Annual Review of  Biomedical Engineering, 19, 221\u2013248-221\u2013248.   Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M.,  Bolton, A., & others. (2017). Mastering the game of go without human knowledge. Nature,  550(7676), 354\u2013359-354\u2013359.   Smit, A., Vrabac, D., He, Y., Ng, A. Y., Beam, A. L., & Rajpurkar, P. (2021). MedSelect: Selective Labeling for  Medical Image Classification Combining Meta-Learning with Deep Reinforcement Learning. arXiv  preprint arXiv:2103.14339.   Stember, J., & Shalu, H. (2020). Deep reinforcement learning to detect brain lesions on MRI: a proof-ofconcept application of reinforcement learning to medical images. arXiv preprint  arXiv:2008.02708.   Stember, J., & Shalu, H. (2021a). Deep reinforcement learning-based image classification achieves perfect  testing set accuracy for MRI brain tumors with a training set of only 30 images. arXiv preprint  arXiv:2102.02895.   Stember, J., & Shalu, H. (2021b). Deep reinforcement learning with automated label extraction from clinical  reports accurately classifies 3D MRI brain volumes. arXiv preprint arXiv:2106.09812.   Sun, S., Hu, J., Yao, M., Hu, J., Yang, X., Song, Q., & Wu, X. (2018). Robust multimodal image registration  using deep recurrent reinforcement learning. Asian conference on computer vision,   Sun, S., Hu, J., Yao, M., Hu, J., Yang, X., Song, Q., & Wu, X. (2019). Robust Multimodal Image Registration  Using Deep Recurrent Reinforcement Learning. In C. V. Jawahar, H. Li, G. Mori, & K. Schindler,  Computer Vision \u2013 ACCV 2018 Cham.  Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.   Van Hasselt, H., Guez, A., & Silver, D. (2016). Deep reinforcement learning with double q-learning.  Proceedings of the AAAI Conference on Artificial Intelligence,   Vithayathil Varghese, N., & Mahmoud, Q. H. (2020). A survey of multi-task deep reinforcement learning.    Electronics, 9(9), 1363.   Vlontzos, A., Alansary, A., Kamnitsas, K., Rueckert, D., & Kainz, B. (2019). Multiple landmark detection  using multi-agent reinforcement learning. International Conference on Medical Image Computing  and Computer-Assisted Intervention,   Wang, G., Zuluaga, M. A., Li, W., Pratt, R., Patel, P. A., Aertsen, M., Doel, T., David, A. L., Deprest, J.,  Ourselin, S., & others. (2018). DeepIGeoS: a deep interactive geodesic framework for medical image  segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(7), 1559\u201315721559\u20131572.   Wang, J., Miao, J., Yang, X., Li, R., Zhou, G., Huang, Y., Lin, Z., Xue, W., Jia, X., & Zhou, J. (2020). Autoweighting for breast cancer classification in multimodal ultrasound. International Conference on  Medical Image Computing and Computer-Assisted Intervention,   Wang, J., Yan, Y., Zhang, Y., Cao, G., Yang, M., & Ng, M. K. (2020). Deep Reinforcement Active Learning for  Medical Image Classification. International Conference on Medical Image Computing and  Computer-Assisted Intervention,   Wang, L., Lekadir, K., Lee, S.-L., Merrifield, R., & Yang, G.-Z. (2013). A general framework for contextspecific image segmentation using reinforcement learning. IEEE transactions on medical imaging,  32(5), 943-956.   Wang, T., Lei, Y., Fu, Y., Wynne, J. F., Curran, W. J., Liu, T., & Yang, X. (2021). A review on medical  imaging synthesis using deep learning and its clinical applications. Journal of Applied Clinical  Medical Physics, 22(1), 11\u201336-11\u201336.   Watkins, C. J. C. H. (1989). Learning from delayed rewards.   Wilson, S. M., & Anagnostopoulos, D. (2021). Methodological Guidance Paper: The Craft of Conducting a  Qualitative Review. Review of Educational Research, 00346543211012755-00346543211012755.   Winkel, D. J., Weikert, T. J., Breit, H.-C., Chabin, G., Gibson, E., Heye, T. J., Comaniciu, D., & Boll, D. T.  (2020). Validation of a Fully Automated Liver Segmentation Algorithm Using Multi-Scale Deep  Reinforcement Learning and Comparison Versus Manual Segmentation. European Journal of  Radiology, 126, 108918-108918.   Xu, B., Liu, J., Hou, X., Liu, B., Garibaldi, J., Ellis, I. O., Green, A., Shen, L., & Qiu, G. (2019). Attention by  selection: A deep selective attention approach to breast cancer classification. IEEE transactions on  medical imaging, 39(6), 1930-1941.   Xu, C., Zhang, D., Chong, J., Chen, B., & Li, S. (2021). Synthesis of gadolinium-enhanced liver tumors on  nonenhanced liver MR images using pixel-level graph reinforcement learning. Medical image  analysis, 69, 101976.   Yang, D., Roth, H., Xu, Z., Milletari, F., Zhang, L., & Xu, D. (2019). Searching learning strategy with  reinforcement learning for 3d medical image segmentation. International Conference on Medical  Image Computing and Computer-Assisted Intervention,   Yang, H., Shan, C., & Kolen, A. F. (2020). Deep Q-Network-Driven Catheter Segmentation in 3D US by  Hybrid Constrained Semi-Supervised Learning and Dual-UNet. International Conference on  Medical Image Computing and Computer-Assisted Intervention,   Ye, J., Xue, Y., Long, L. R., Antani, S., Xue, Z., Cheng, K. C., & Huang, X. (2020). Synthetic sample selection  via reinforcement learning. International Conference on Medical Image Computing and ComputerAssisted Intervention,   Zhang, D., Chen, B., & Li, S. (2021). Sequential conditional reinforcement learning for simultaneous  vertebral body detection and segmentation with modeling the spine anatomy  [https://doi.org/10.1016/j.media.2020.101861]. Medical image analysis, 67, 101861-101861.   Zhao, G., Meyerand, M. E., & Birn, R. M. (2020). Bayesian Conditional GAN for MRI Brain Image Synthesis.  In: arXiv.  Zheng, C., Si, X., Sun, L., Chen, Z., Yu, L., & Tian, Z. (2021). Multi-agent reinforcement learning for prostate  localization based on multi-scale image representation. International Symposium on Artificial  Intelligence and Robotics 2021,     ",
    "title": "Reinforcement Learning in Medical Image Analysis: ",
    "paper_info": " \n \n4. Discussion \nDesigning the medical image analysis as the RL problems is not an easy thing. Generally, the pipeline \ncan be concluded in four steps: (i) thoroughly understand the environment; (ii) correctly choose an \nalgorithm that would work for your problem; (iii) meticulously design the states, actions, and rewards; (iv) \npatiently train the framework to converge and validate the results. Though the RL for medical image \nanalysis is still a new research field and the way to formulate the problems may vary from person to person, \nwe can still conclude some interesting strategies from this works. While some challenges still exist, we are \nstill optimistic about the perspective of this field. \nSingle Agent vs. Multi Agent \nMulti-agent reinforcement (MARL) is one of the trends in recent years, aiming to improve the \nperformance of single agent when facing large-scale and complicated environments. We have witnessed a \nfew attempts to use multi-agent frameworks to solve some complex medical image analysis tasks. In these \nworks, the agents collaborate and share their knowledge and experience to obtain the maximum mutual \nreward. The joint actions of all agents lead to the state's transition, and each agent's reward depends on the \nmutual strategy. It is worthy to note that the MARL may not always work. First of all, the reward \nmechanism of the MARL is more complicated than its single-agent counterpart. It is crucial to design a \nproper reward signal to improve the speed of learning and convergence. Besides, the enlarged (joint) state \nand action space may consume more computation power and decrease the efficiency of the RL framework. \nMultiscale Strategy \nOne common strategy in RL for medical image detection and segmentation problems is the multiscale \nsearching strategy. The agent will first perform the task at the coarsest level (usually by sampling the \noriginal image). An ROI is extracted and rescaled to a finer resolution, and the task is performed on this \nROI again. This process is repeated iteratively until the finest resolution is reached. This multiscale, fine-\nto-coarse strategy is beneficial for training RL frameworks and saves computational resources and time. \nModel-Free vs. Model-Based \nThe agent-based frameworks we have reviewed all belong to the model-free category. However, the \nmodel-based algorithm is another important subclass of RL. One possible reason why researchers did not \nattempt to use model-based RL is that it is hard to form the internal model of the environment considering \nthe high dimensionality and large size of medical image data. However, the model-based models have their \nown advantage over the model-free ones, which is the higher sample efficiency. We are looking forward \nto future works on model-based RL for medical image tasks with small-scale labeled data. \n4.1. Challenges \nMany challenges still impede medical imaging researchers from applying RL in their works. \nThe long training time and heavily consumed computational resources are something we can't ignore \nbefore starting RL-related research. Though RL has proved its efficiency in the inference phase of many \ntasks, learning from numerous trials and errors means it often takes at least a few days longer on some of \nthe cutting-edge GPUs. \nBesides, as we mentioned before, the design of the RL problems can be tricky. A slightly different \ndesign of the state, action, or reward may lead to a totally different performance (some models may fail to \nconverge). The choice of hyperparameters of the RL frameworks also depends on the designers' experience \nwith low explainability. Researchers may take days to experiment to find the parameters that work. \nThe low stability and reproducibility are other primary concerns (Khetarpal et al., 2018). Following the \nsame workflows, some RL-agent may fail to work as well as described in the original paper. It is even \nharder to perform similarly when the input data source is changed. Even more challenging is that the works \nhave been scarce, but most of the papers in this field will not make their code publicly available. \nOne last but not least, there have been some more accessible state-of-the-art methods to solve some \ntypes of medical imaging problems, and RL did not show a prominent advantage over them. For example, \n",
    "GPTsummary": "- (1): The research background of this article is medical image analysis, which is traditionally conducted by physicians or medical physicists and leads to low efficiency and biases due to personal experience. Many machine learning methods have been applied in the past decade to improve the accuracy and reliability of diagnosis and prognosis, but attempts to use reinforcement learning are scarce.\n\n- (2): The past methods in medical image analysis were mostly supervised and unsupervised learning models, which lack the ability to adapt to new environments and situations. Reinforcement learning, on the other hand, can learn from interacting with the environment and can handle sequential decision-making problems, making it a promising solution for medical image analysis. The motivation behind this approach is well-founded in the potential for reducing biases and increasing efficiency in the medical industry.\n\n- (3): The research methodology proposed in this paper is a review article that collects and categorizes published papers from Google Scholar and PubMed on the applications of reinforcement learning in medical image analysis. The papers are reviewed based on the type of image analysis task and the reinforcement learning models used, and limitations and possible improvements of the reviewed approaches are discussed.\n\n- (4): The methods in this paper are applied to landmark detection in medical images, which is an important task for accurate diagnosis and prognosis. The performance achieved by reinforcement learning approaches in this task is discussed in the paper, and the potential for improving efficiency and reducing biases in the medical industry is highlighted. However, no numerical value is provided to evaluate the performance of the methods.\n\n\n\n\n\n8. Conclusion:\n - (1): The significance of this work lies in exploring the potential of using reinforcement learning in medical image analysis, which can reduce biases and increase efficiency in the medical industry. The focus on landmark detection is important for accurate diagnosis and prognosis.\n - (2): Innovation point: The use of reinforcement learning in medical image analysis is a novel approach that can handle sequential decision-making problems, making it a promising solution for the field. Performance: The article discussed the performance of reinforcement learning approaches in landmark detection but did not provide numerical evaluation. Workload: The research methodology proposed in this paper, a review article that collects and categorizes published papers, is a feasible and efficient way to examine the state-of-the-art research in the field.\n\n\n",
    "GPTmethods": " not found",
    "GPTconclusion": "\n"
}