{
    "title": "",
    "paper_info": "A PREPRINT \n5 \n \n \n \n \nAlgorithm 1 An overview of steps involved in resource allocation using RL algorithm \nCreate simulation environment \nCreate memory \nCreate policy net \nCreate target net \nwhile Training episodes not complete do \nReset simulation \nwhile not in terminal state do \nRecommend action from policy net \nPass action to simulation \nIncrease time-step in simulation \nReceive (next state, reward, terminal,info) from simulation \nStore (state, next state, reward, terminal)to memory \nUpdate policy net \nend \nUpdate target net \nend \nEvaluation for performance of policy net \n \n4 Results \n \n(a) Double Deep Q Learning \n(b) D3 Q Learning \n(c) Noisy D3 Q Learning \n(d) Prioritised Replay DDQN \n \n \n \n \n(e) Prioritised Replay Noisy D3 \nQ Learning \n \n(f) Bootstrapped Aggregation \n(\u2019Bagging\u2019) D3 Q Learning \n(g) Noisy Bootstrapped Aggre- (h) Proposed Noisy Boot- \ngation (\u2019Bagging\u2019) D3Q Learn- strapped \nAggregation \ning with Prioritised Replay (\u2019Bagging\u2019) D3 Q Learning \nFigure 3: Exploration vs Reward \n \nThe result obtained after simulation choosing various types of reinforcement learning algorithms right from double Q \nnetwork to noisy bootstrap aggregation duelling double Q network with prioritized replay showed that noisy bootstrap \naggregation D3 Q learning approach was supposed to be the best algorithm in terms of efficiency for resource allocation. \nHence, effective for operation of resource allocation in robotic control systems. Few algorithms having prioritized \nreplay suffered from under capacity for prolonged amount of time with significantly less accuracy due to reason \n",
    "GPTsummary": "- (1): The research background of this article is to solve the problem of resource allocation in an uncertain system environment using deep reinforcement learning techniques.\n\n\n- (2): Past methods primarily relied on predefined techniques and modern deep learning methods, which fail to meet the requirements in uncertain system environments. The article is well motivated as it demonstrates that deep reinforcement learning has the ability to adapt to new environments for a prolonged period of time.\n\n\n- (3): The proposed research methodology utilizes various deep reinforcement learning algorithms, primarily based on Q learning approaches, for resource allocation. The paper provides a detailed comparative analysis on various deep reinforcement learning methods by applying different components to modify the architecture of reinforcement learning with the use of noisy layers, prioritized replay, bagging, dueling networks, and other related combinations to obtain improvement in terms of performance and reduction of computational cost.\n\n\n- (4): The proposed methodology is evaluated on a simulated environment for resource allocation achieving efficiency of 97.7% by maximizing reward with significant exploration in the given environment. The performance achieved demonstrates that the proposed methodology is effective in solving the problem of resource allocation in uncertain environments.\n\n\n\n\n\n8. Conclusion:\n\n- (1): The significance of this piece of work is to propose a deep reinforcement learning approach to solve the resource allocation problem in uncertain system environments. The paper demonstrates that deep reinforcement learning has the ability to adapt to new environments for a prolonged period of time.\n\n- (2): Innovation point: This article innovates in applying deep reinforcement learning algorithms to solve complex problems in uncertain system environments. It also proposes a method to modify the architecture of reinforcement learning by using various components to enhance the performance and reduce the computational cost. \nPerformance: The proposed methodology achieves a high efficiency of 97.7% in resource allocation in a simulated environment. However, the paper lacks comparison with other state-of-the-art methods, which may affect the objectiveness of the evaluation. \nWorkload: The paper provides a detailed comparative analysis on various deep reinforcement learning methods, but some description of the methods is relatively concise and lacks sufficient detail.\n\n\n",
    "GPTmethods": " not found",
    "GPTconclusion": "- (1): The significance of this piece of work is to propose a deep reinforcement learning approach to solve the resource allocation problem in uncertain system environments. The paper demonstrates that deep reinforcement learning has the ability to adapt to new environments for a prolonged period of time.\n\n- (2): Innovation point: This article innovates in applying deep reinforcement learning algorithms to solve complex problems in uncertain system environments. It also proposes a method to modify the architecture of reinforcement learning by using various components to enhance the performance and reduce the computational cost. \nPerformance: The proposed methodology achieves a high efficiency of 97.7% in resource allocation in a simulated environment. However, the paper lacks comparison with other state-of-the-art methods, which may affect the objectiveness of the evaluation. \nWorkload: The paper provides a detailed comparative analysis on various deep reinforcement learning methods, but some description of the methods is relatively concise and lacks sufficient detail.\n\n\n"
}