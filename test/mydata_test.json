[{"paper_info": "LaMini-LM: A Diverse Herd of Distilled Models\nfrom Large-Scale Instructions\nMinghao Wu1,2\u2217Abdul Waheed1 Chiyu Zhang1,3 Muhammad Abdul-Mageed1,3 Alham Fikri Aji1\n1Mohamed bin Zayed University of Arti\ufb01cial Intelligence\n2Monash University\n3The University of British Columbia\n{minghao.wu,abdul.waheed,chiyu.zhang,muhammad.mageed,alham.fikri}@mbzuai.ac.ae\nAbstract\nLarge language models (LLMs) with instruc-\ntion \ufb01netuning demonstrate superior genera-\ntive capabilities. However, these models are\nresource intensive. To alleviate this issue, we\nexplore distilling knowledge from instruction-\ntuned LLMs to much smaller ones. To this end,\nwe carefully develop a large set of 2.58M in-\nstructions based on both existing and newly-\ngenerated instructions.\nIn addition to being\nsizeable, we design our instructions to cover\na broad set of topics to ensure. A thorough in-\nvestigation of our instruction data demonstrate\ntheir diversity, and we generate responses for\nthese instructions using gpt-3.5-turbo. We\nthen exploit the instructions to tune a host\nof models, dubbed LaMini-LM, of varying\nsizes, both from the encoder-decoder as well\nas the decoder-only families.\nWe evaluate\nour models both automatically (on 15 differ-\nent NLP benchmarks) and manually. Results\nshow that our proposed LaMini-LM are on par\nwith competitive baselines while being nearly\n\u00d710 smaller in size.1\n1\nIntroduction\nLarge language models (LLMs) with instruction\ntuning are capable of generating remarkable out-\nputs for a wide range of use cases (Ouyang et al.,\n2022; Wei et al., 2022; Sanh et al., 2022; Chung\net al., 2022; OpenAI, 2023). However, these mod-\nels usually have billions of parameters, which re-\nquire massive computational resources for both\ntraining and inference (Brown et al., 2020; Thop-\npilan et al., 2022; Hoffmann et al., 2022; Chowd-\nhery et al., 2022). Kaplan et al. (2020) suggest\nthat the performance of LLMs scales proportion-\nally with model and dataset size. Consequently,\nscaling the models raises many issues such as those\nrelated to the energy footprint (Strubell et al., 2019).\n\u2217 work done while visiting MBZUAI\n1Our code, model checkpoints, and dataset are available at\nhttps://github.com/mbzuai-nlp/LaMini-LM\n+\nGenerate\nExisting\nInstructions\nGPT2\n+\nGenerate\nFine-tune\nT5\nNeo\nLaMini-LM\nC.\nModels\nSeed\nInstructions\nSynthetic\nInstructions\nSynthetic \nResponses\nLaMini-Instruction dataset\nFigure 1: Overview of LaMini-LM\nMoreover, the accessibility of large models is a real\nconcern for many NLP practitioners due to lim-\nited access to computing resources (Nityasya et al.,\n2020).\nIn this work, we present LaMini-LM, a collec-\ntion of language models that are notably smaller\nin size than most existing instruction-tuned mod-\nels. We develop LaMini-LM models by employing\nsequence distillation (also known as of\ufb02ine distilla-\ntion) (Kim and Rush, 2016) from LLMs. Although\nsimilar attempts have been made in recent work\n(e.g., (Taori et al., 2023; Chiang et al., 2023; Anand\net al., 2023)), there are several gaps in this literature\nthat we aim to address. Speci\ufb01cally, these works\noften (i) provide a small-scale distilled dataset (ii)\nthat is not necessarily diverse, and a (iii) limited\nnumber of models (typically only one), (iv) with-\nout comprehensive evaluation nor analysis of the\nmodels\u2019 performance. Furthermore, many of the\ndistilled models resulting from prior work tend to\nstill be relatively computationally intensive. That\nis, parameters of these recent models usually range\nfrom 7B to 13B, making them dif\ufb01cult to deploy in\nresource-constrained settings especially for under-\nresourced institutions.\nTo alleviate these issues, we \ufb01rstly generate a\nlarge-scale of\ufb02ine distillation dataset comprising\narXiv:2304.14402v1  [cs.CL]  27 Apr 2023\n"}, {"paper_info": "We\u2019re Afraid Language Models Aren\u2019t Modeling Ambiguity\nAlisa Liu\u2661\nZhaofeng Wu\u2666\nJulian Michael\u2660\nAlane Suhr\u2663\nPeter West\u2661\nAlexander Koller\u2665\u2663\nSwabha Swayamdipta\u2662\nNoah A. Smith\u2661\u2663\nYejin Choi\u2661\u2663\n\u2661Paul G. Allen School of Computer Science & Engineering, University of Washington\n\u2663Allen Institute for Arti\ufb01cial Intelligence\n\u2662University of Southern California\n\u2665Saarland University\n\u2660New York University\n\u2666Massachusetts Institute of Technology\nalisaliu@cs.washington.edu\nAbstract\nAmbiguity is an intrinsic feature of natural lan-\nguage. Managing ambiguity is a key part of\nhuman language understanding, allowing us\nto anticipate misunderstanding as communica-\ntors and revise our interpretations as listeners.\nAs language models (LMs) are increasingly\nemployed as dialogue interfaces and writing\naids, handling ambiguous language is critical\nto their success. We characterize ambiguity in\na sentence by its effect on entailment relations\nwith another sentence, and collect AMBIENT,1\na linguist-annotated benchmark of 1,645 exam-\nples with diverse kinds of ambiguity. We de-\nsign a suite of tests based on AMBIENT, pre-\nsenting the \ufb01rst evaluation of pretrained LMs\nto recognize ambiguity and disentangle possi-\nble meanings. We \ufb01nd that the task remains ex-\ntremely challenging, including for the recent\nGPT-4, whose generated disambiguations are\nconsidered correct only 32% of the time in\nhuman evaluation, compared to 90% for dis-\nambiguations in our dataset. Finally, to illus-\ntrate the value of ambiguity-sensitive tools, we\nshow that a multilabel NLI model can \ufb02ag po-\nlitical claims in the wild that are misleading\ndue to ambiguity. We encourage the \ufb01eld to re-\ndiscover the importance of ambiguity for NLP.\n1\nIntroduction\nAmbiguity seems to be an essential, in-\ndispensable element for the transfer of\ninformation from one place to another by\nwords. \u2014 Thomas (1974), as referenced\nin the epilogue of Grosz (1977)\nAmbiguity is an intrinsic feature of language, al-\nlowing speakers to balance ef\ufb01ciency and clarity\nin communication (Zipf, 1949; Piantadosi et al.,\n2012). Language understanding thus requires rec-\nognizing the presence of multiple interpretations:\n1Data and code can be found at https://github.com/\nalisawuffles/ambient\nFigure 1: Ambiguity can be the result of innocent mis-\ncommunication (top), or deliberately used to mislead\none\u2019s listeners (bottom). For instance, if the cat is con-\nfused about its whereabouts after leaving the house,\nthen it is lost in the sense of being unable to \ufb01nd its way\n(entailment edge); if it has not returned home in many\ndays, then it is lost in the sense that others cannot lo-\ncate it (neutral edge). Each example in AMBIENT con-\ntains a set of labels corresponding to plausible readings,\nalong with a disambiguating rewrite for each reading.\nas communicators, we anticipate the possibility of\nmisunderstanding; as listeners, we ask clarifying\nquestions, disambiguate meanings on the basis of a\nwide range of contextual factors, and backtrack and\nrevise our earlier interpretations as needed. Beyond\nunintended miscommunication, ambiguity is also\nan effective tool for sending covert messages, e.g.,\nout of politeness or to mislead one\u2019s listeners while\navoiding accountability (see Figure 1).\nAs language models (LMs) are increasingly em-\nployed to act as dialogue agents (OpenAI, 2022;\nShuster et al., 2022) or to aid human communica-\ntion as writing aids (Lee et al., 2022), being able\nto work with ambiguous language will make them\nmore effective. This skill would support adaptation\nto different contexts, clearer communication, and\nidenti\ufb01cation of misleading or deceptive language.\nYet, the ability of pretrained LMs to recognize am-\nbiguity and disentangle possible meanings remains\nunstudied, partly because ambiguous instances are\nsystematically excluded in the curation of bench-\narXiv:2304.14399v1  [cs.CL]  27 Apr 2023\n"}, {"paper_info": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\nJINGFENG YANG\u2217, Amazon, USA\nHONGYE JIN\u2217, Department of Computer Science and Engineering, Texas A&M University, USA\nRUIXIANG TANG\u2217, Department of Computer Science, Rice University, USA\nXIAOTIAN HAN\u2217, Department of Computer Science and Engineering, Texas A&M University, USA\nQIZHANG FENG\u2217, Department of Computer Science and Engineering, Texas A&M University, USA\nHAOMING JIANG, Amazon, USA\nBING YIN, Amazon, USA\nXIA HU, Department of Computer Science, Rice University, USA\nThis paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs)\nin their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from\nthe perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a\ndetailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as\nknowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities,\nand considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and\nlimitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated\nwith each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such\nas efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide\naims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the\nsuccessful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly\nupdated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide.\nCCS Concepts: \u2022 Computing methodologies \u2192 Natural language processing; Natural language generation; Machine trans-\nlation.\nAdditional Key Words and Phrases: Large Language Models, Neural Language Processing, Practical Guide, ChatGPT\n1\nINTRODUCTION\nIn recent years, the rapid development of Large language Models has been revolutionizing the field of natural language\nprocessing [12, 128, 131]. These powerful models have shown great potential in addressing a variety of NLP tasks,\nranging from natural language understanding (NLU) to generation tasks, even paving the way to Artificial General\nIntelligence (AGI). However, utilizing these models effectively and efficiently requires a practical understanding of their\ncapabilities and limitations, as well as the data and tasks involved in NLP.\nTo provide a guide for partitioners and end-users, this work focuses on the practical aspects of working with LLMs\nin downstream NLP tasks. This guide aims to provide practical advice on why or why not to choose LLMs for a given\n\u2217These authors contributed equally.\nAuthors\u2019 addresses: Jingfeng Yang, jingfengyangpku@gmail.com, Amazon, USA; Hongye Jin, jhy0410@tamu.edu, Department of Computer Science\nand Engineering, Texas A&M University, USA; Ruixiang Tang, rt39@rice.edu, Department of Computer Science, Rice University, USA; Xiaotian Han,\nhan@tamu.edu, Department of Computer Science and Engineering, Texas A&M University, USA; Qizhang Feng, qf31@tamu.edu, Department of Computer\nScience and Engineering, Texas A&M University, USA; Haoming Jiang, jhaoming@amazon.com, Amazon, USA; Bing Yin, alexbyin@amazon.com, Amazon,\nUSA; Xia Hu, xia.hu@rice.edu, Department of Computer Science, Rice University, USA.\n1\narXiv:2304.13712v2  [cs.CL]  27 Apr 2023\n"}]